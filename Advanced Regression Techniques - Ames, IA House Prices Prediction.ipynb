{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Regression Techniques - Ames, IA Housing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to determine the price of housing in the city of Ames, IA using real estate data and different models\n",
    "\n",
    "(Decision Tree, Random Forest, XGBoost Regression)\n",
    "\n",
    "Addtionally, features such as Lot Size, Number of Bedrooms and the Age of the House will be considered\n",
    "\n",
    "Root Mean Squared Error (RMSE) is the method of Regression that will be selected to predict real estate prices using real estate features. According to Wikipedia, RMSE is defined as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root-mean-square deviation (**RMSD**) or root-mean-square error **(RMSE)** is a frequently used measure of the differences between values (sample or the effect values) predicted by a model or an estimator and the values observed. The **RMSD** represents the square root of the second sample moment of the differences between predicted values and observed values or the quadratic mean of these differences. These deviations are called residuals when the calculations are performed over the The effect sample that was used for estimation and are called errors (or The effect errors) when computed out-of-sample. The **RMSD** serves to aggregate the magnitudes of the errors in predictions for various data points into a single measure of predictive power. **RMSD** is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSD** is non-negative, and a value of 0 (almost never achieved in practice) would indicate a perfect fit to the data. In general, a **lower RMSD** is better than a higher one. However, comparisons across different types of data would be invalid because the measure is dependent on the scale of the numbers used.\n",
    "\n",
    "**RMSD** is the square root of the average of squared errors. The effect of each error on **RMSD** is proportional to the size of the squared error; thus larger errors have a disproportionately large effect on **RMSD**. Consequently, **RMSD** is sensitive to outliers. The root-mean-square deviation (**RMSD**) or root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample or The effect values) predicted by a model or an estimator and the values observed. The **RMSD** represents the square root of the second sample moment of the differences between predicted values and observed values or the quadratic mean of these differences. These deviations are called residuals when the calculations are performed over the The effect sample that was used for estimation and are called errors (or The effect errors) when computed out-of-sample. The **RMSD** serves to aggregate the magnitudes of the errors in predictions for various data points into a single measure of predictive power. **RMSD** is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**RMSD** is in effect non-negative, and a value of 0 (almost never achieved in practice) would indicate a perfect fit to the data. In general, a lower **RMSD** is better than a higher one. However, comparisons across different types of data would be invalid because the measure is dependent on the scale of the numbers used.\n",
    "\n",
    "**RMSD** is the square root of the average of squared errors. The effect of each error on **RMSD** is proportional to the size of the squared error; thus larger errors have a disproportionately large  effect on **RMSD**. Consequently, **RMSD** is sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Description:\n",
    "\n",
    "       NA\tNo Garage\n",
    "              \n",
    "       GarageCond: Garage condition\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical/Average\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "       NA\tNo Garage\n",
    "              \n",
    "       PavedDrive: Paved driveway\n",
    "\n",
    "       Y\tPaved \n",
    "       P\tPartial Pavement\n",
    "       N\tDirt/Gravel\n",
    "              \n",
    "       WoodDeckSF: Wood deck area in square feet\n",
    "\n",
    "       OpenPorchSF: Open porch area in square feet\n",
    "\n",
    "       EnclosedPorch: Enclosed porch area in square feet\n",
    "\n",
    "       3SsnPorch: Three season porch area in square feet\n",
    "\n",
    "       ScreenPorch: Screen porch area in square feet\n",
    "\n",
    "       PoolArea: Pool area in square feet\n",
    "\n",
    "       PoolQC: Pool quality\n",
    "              \n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       NA\tNo Pool\n",
    "              \n",
    "       Fence: Fence quality\n",
    "              \n",
    "       GdPrv\tGood Privacy\n",
    "       MnPrv\tMinimum Privacy\n",
    "       GdWo\tGood Wood\n",
    "       MnWw\tMinimum Wood/Wire\n",
    "       NA\tNo Fence\n",
    "\n",
    "       MiscFeature: Miscellaneous feature not covered in other categories\n",
    "              \n",
    "       Elev\tElevator\n",
    "       Gar2\t2nd Garage (if not described in garage section)\n",
    "       Othr\tOther\n",
    "       Shed\tShed (over 100 SF)\n",
    "       TenC\tTennis Court\n",
    "       NA\tNone\n",
    "              \n",
    "       MiscVal: $Value of miscellaneous feature\n",
    "\n",
    "       MoSold: Month Sold (MM)\n",
    "\n",
    "       YrSold: Year Sold (YYYY)\n",
    "\n",
    "       SaleType: Type of sale\n",
    "              \n",
    "       WD \tWarranty Deed - Conventional\n",
    "       CWD\tWarranty Deed - Cash\n",
    "       VWD\tWarranty Deed - VA Loan\n",
    "       New\tHome just constructed and sold\n",
    "       COD\tCourt Officer Deed/Estate\n",
    "       Con\tContract 15% Down payment regular terms\n",
    "       ConLw\tContract Low Down payment and low interest\n",
    "       ConLI\tContract Low Interest\n",
    "       ConLD\tContract Low Down\n",
    "       Oth\tOther\n",
    "              \n",
    "       SaleCondition: Condition of sale\n",
    "\n",
    "       Normal\tNormal Sale\n",
    "       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n",
    "       AdjLand\tAdjoining Land Purchase\n",
    "       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n",
    "       Family\tSale between family members\n",
    "       Partial\tHome was not completed when last assessed (associated with New Homes)\n",
    "       \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %reload_ext autotime\n",
    "except:\n",
    "    %pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.offline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "  \n",
    "# import sklearn machine learning libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "%pip install shap\n",
    "import shap\n",
    "\n",
    "%pip install xgboost\n",
    "from xgboost import plot_importance\n",
    "\n",
    "%pip install category_encoders\n",
    "\n",
    "# XGBoost ML libraries\n",
    "import math\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# Formatting options\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the training dataset\n",
    "\n",
    "url = 'https://github.com/patty-olanterns/RealEstateAmesIA/blob/main/train.csv?raw=true'\n",
    "df = pd.read_csv(url, low_memory=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data structure of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Id column\n",
    "df.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = ['MSSubClass', 'MSZoning'] \n",
    "df[object_cols] = df[object_cols].astype('object')\n",
    "\n",
    "# Convert all int and float64 to float32\n",
    "num_cols = df.select_dtypes(exclude=['object']).columns\n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce', downcast='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of attributes with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null data and sort by the top 10 columns\n",
    "df.isnull().sum(axis=0).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19/80 attributes are missing values. These cells can be filled in with imputation\n",
    "or other methods or deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there a correlation (+ or -) between specific house features and the SalePrice?\n",
    "\n",
    "Example:\n",
    " - Does a renovation increase the SalePrice?\n",
    " - By how much?\n",
    " - How much of an impact does the GarageSize(1 car, 2 car) have on the SalePrice?\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 10 positively correlated features with target (SalePrice)\n",
    "df.corrwith(df['SalePrice']).sort_values(ascending=False).head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data using a heat map\n",
    "corr_vals = df.corr()\n",
    "\n",
    "# Check correlation between SalePrice and attributes\n",
    "plt.rcParams['figure.figsize'] = 25, 25\n",
    "plot_map = sns.heatmap(corr_vals,annot=True,fmt=\".2f\",cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot AveragePriceOfHome by Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average price by neighborhood\n",
    "a = pd.DataFrame(df.groupby('Neighborhood')['SalePrice'].mean().sort_values(ascending=True))\n",
    "a.plot.barh(figsize = (8,5))\n",
    "plt.xlabel('Price (USD)')\n",
    "plt.title('Average Price of Home by Neighborhood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What factors should we consider for SalePrice? \n",
    "\n",
    "Factors to consider: \n",
    "\n",
    "- Year of Renovations (YearRemodAdd)\n",
    "- Overall Quality\n",
    "- Kitchen\n",
    "- Roof\n",
    "- Number of years since last Renovation ('YearsSinceReno')\n",
    "- Age of House (YearBuilt)\n",
    "- Total Square Footage (TotalSF)\n",
    "- Lot Size\n",
    "- Area of town (crime, race, earnings, etc.)\n",
    "- Condition of House (HouseQuality)\n",
    "- Basement quality etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine 1st, 2nd and finished basement sqft together (1stFlrSF, 2ndFlrSF)\n",
    "df['TotalSF'] = df['1stFlrSF'] + df['2ndFlrSF'] + df['TotalBsmtSF']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine outliers for TotalSF\n",
    "fig = px.histogram(df, x='TotalSF', \n",
    "                   marginal='box',\n",
    "             histnorm = 'percent',\n",
    "             title='TotalSF Histogram')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out all outlier values with a z-score > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter other columns based on a single column\n",
    "\n",
    "from scipy import stats\n",
    "df_filtered = df[(np.abs(stats.zscore(df['TotalSF']) < 3))]\n",
    "\n",
    "print(\"Old Shape: \", df.shape)\n",
    "print(\"New Shape: \", df_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "- Features and target selection\n",
    "- Train-Test Split\n",
    "- Numeric/Category Pipeline Setup\n",
    "  - Define numerical and categorical columns in training data\n",
    "  - Replace null numeric values with SimpleImputer()\n",
    "  - Replace null categorical values (string, object, bool) with most frequent values by column\n",
    "  - Encode each categorical value as unique category using OneHotEncoder()\n",
    "  - Setup preprocessor ColumnTransformer Pipeline with numeric and category transformers as steps\n",
    "    in process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Target selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in df.columns if x not in ['SalePrice']]\n",
    "X = df[features] # Prediction variable\n",
    "y = df['SalePrice'] # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric and Category Pipeline setup \n",
    " - XGBoost can ONLY interpret numeric values!\n",
    " - In order to interpret category and numeric values, all category values\n",
    "   must be encoded using OneHotEncoder. Each string feature will be its own category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data up in to numerical data (int and float) and categorical \n",
    "# data (objects, names, words etc.)\n",
    "num_cols = [cname for cname in X_train.columns \n",
    "            if X_train[cname].dtype == \"float32\"]\n",
    "\n",
    "category_cols = [cname for cname in X_train.columns \n",
    "                 if X_train[cname].nunique() < 22 and \n",
    "                 X_train[cname].dtype == \"object\"]\n",
    "\n",
    "# SimpleImputer is a function that replaces null cell values with the mean,\n",
    "# median, most frequent or a fixed value based on the dataset used\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# The same process can be applied to categorical values (strings, objects, etc.)\n",
    "# and automated using the Pipeline function\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Transform all data in columns using the preprocessor and ColumnTransformer function\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, category_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Root Mean Squared Log Error function (RMSLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSLE (Root Mean Square Log Error) must be used for this dataset to compare the predicted\n",
    "data with the valid data. It's not a default scoring metric available\n",
    "as a tool in Sci-kit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_log_error(y_valid, y_preds):\n",
    "    # Calc rmse of log(y_test) and log(y_pred)\n",
    "    \n",
    "    if len(y_preds) != len(y_valid): return 'error_mismatch'\n",
    "    y_preds_new = [math.log(x) for x in y_preds]\n",
    "    y_valid_new = [math.log(x) for x in y_valid]\n",
    "    return mean_squared_error(y_valid_new,y_preds_new,squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model from sklearn\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Setup a Pipeline processing function\n",
    "tree_clf = Pipeline(steps=[('preprocessor',preprocessor),\n",
    "                           ('tree_model',tree_model)\n",
    "                          ])\n",
    "\n",
    "\n",
    "# Fit the training dataset to the model\n",
    "tree_clf.fit(X_train,y_train)\n",
    "\n",
    "# Set tree_preds to the test feature data (X_test)\n",
    "tree_preds = tree_clf.predict(X_test)\n",
    "\n",
    "# Print the RMSLE results\n",
    "print('RMSLE:', root_mean_squared_log_error(y_test,tree_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model II: Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rand_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('rf',rf_model)\n",
    "                           ])\n",
    "\n",
    "# Fit the training data to the model\n",
    "rand_clf.fit(X_train, y_train)\n",
    "\n",
    "rand_preds = rand_clf.predict(X_test)\n",
    "\n",
    "print('RMSLE:', root_mean_squared_log_error(y_test, rand_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model III: XGB Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pipeline process and fit train-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=1000,\n",
    "                         max_depth=5, min_child_weight=1, \n",
    "                         gamma=0, \n",
    "                         booster='gbtree', \n",
    "                         learning_rate=0.02, \n",
    "                         objective='reg:squarederror', \n",
    "                         random_state=42)\n",
    "\n",
    "# Run Pipeline\n",
    "xgb_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('xgb_model', xgb_model)\n",
    "                          ])\n",
    "\n",
    "# Fit the model\n",
    "xgb_clf.fit(X_train, y_train, xgb_model__verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine feature importance in XGBoost model\n",
    "\n",
    "- Calc beta coefficients for each feature in the model\n",
    "- Size of the beta coefficients for each feature will affect the Sale Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb_clf.named_steps['xgb_model']\n",
    "\n",
    "feature_important = model.get_booster().get_score(importance_type='gain')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "data.nlargest(10, columns=\"score\").plot(kind='barh', figsize = (20,10)) ## plot top 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "\n",
    "feature_important = model.get_booster().get_score(importance_type='gain')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"SCORE\"]).sort_values(by = \"SCORE\", ascending=False)\n",
    "data['FEATURE_IMPORTANCE_KEY'] = data.index\n",
    "data.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# The size of the beta coefficient for each Feature in the model affects the SalePrice by a certain amount\n",
    "df_beta = pd.DataFrame(zip(X_train.columns, model.get_booster().get_score(importance_type='gain')), columns=['FEATURE','FEATURE_IMPORTANCE_KEY'])\n",
    "\n",
    "df_feat = pd.merge(df_beta, data, on='FEATURE_IMPORTANCE_KEY', how='inner')\n",
    "df_feat = df_feat.sort_values(by='FEATURE_IMPORTANCE_KEY',ascending=False).reset_index(drop=True)\n",
    "df_feat['FEATURE_IMPORTANCE_KEY'] = df_feat['FEATURE_IMPORTANCE_KEY'].str.replace('f','')\n",
    "df_feat['FEATURE_IMPORTANCE_KEY'] = df_feat['FEATURE_IMPORTANCE_KEY'].astype('int32')\n",
    "df_feat['SCORE'] = df_feat['SCORE']  / 10**6\n",
    "df_feat = df_feat.sort_values(by='SCORE',ascending=False).reset_index(drop=True)\n",
    "df_feat = df_feat.head(10)\n",
    "\n",
    "# Display top 10 features for XGBoost model\n",
    "fig = px.bar(df_feat,\n",
    "             x='SCORE',\n",
    "             y='FEATURE',\n",
    "             hover_data=['FEATURE',\n",
    "                        'SCORE'],\n",
    "            title='XGBoost Regression Model: Feature Importance Score - Importance Type = Gain')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display predicted values (RMSLE) in XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds = xgb_clf.predict(X_test)\n",
    "\n",
    "print('RMSLE:', root_mean_squared_log_error(y_test, xgb_preds))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare model values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decision Tree RMSLE:', root_mean_squared_log_error(y_test, tree_preds))\n",
    "print('Random Forest RMSLE:', root_mean_squared_log_error(y_test, rand_preds))\n",
    "print('XGBoost Regressor RMSLE:', root_mean_squared_log_error(y_test, xgb_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model performed the best out of the three models as \n",
    "it had the lowest RMSLE score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GridSearchCV (CrossValidation) to select best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the GridSearchCV model to determine the best parameters to select for \n",
    "Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\"xgb_model__nlearning_rate\": (0.05, 0.10, 0.15),\n",
    "                        \"xgb_model__nmax_depth\": [6],\n",
    "                        \"xgb_model__nmin_child_weight\": [1],\n",
    "                        \"xgb_model__ngamma\":[0.0, 0.1, 0.2],\n",
    "                        \"xgb_model__ncolsample_bytree\":[ 0.3, 0.4]}\n",
    "\n",
    "grid = GridSearchCV(xgb_clf, \n",
    "            cv=3, param_grid=param_grid, \n",
    "            scoring=None, verbose=True, n_jobs=-1)\n",
    "\n",
    "\"\"\"\n",
    "grid = GridSearchCV(xgb_clf,\n",
    "                    param_grid=param_grid,\n",
    "                    n_jobs=-1,\n",
    "                    cv=3,\n",
    "                    scoring='accuracy')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print('\\n All results:')\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Best estimator:')\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Best score:')\n",
    "print(grid.best_score_ * 2 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Best parameters:')\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Feature Importances:')\n",
    "feat_array = grid.best_estimator_.named_steps[\"xgb_model\"].feature_importances_\n",
    "df_feat = pd.DataFrame(feat_array.reshape(feat_array.shape), columns=['FEAT_IMPOR_SCORE']).sort_values(by='FEAT_IMPOR_SCORE',ascending=False).reset_index(drop=True)\n",
    "df_feat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model IV: Run high performance XGB regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.6, gamma=0.5, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.02, max_delta_step=0, max_depth=4,\n",
    "             min_child_weight=1, monotone_constraints='()',\n",
    "             n_estimators=1000, n_jobs=0, num_parallel_tree=1, random_state=42,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "hp_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('hp_model', hp_model)\n",
    "                     ])\n",
    "\n",
    "hp_clf.fit(X_train, y_train, hp_model__verbose=False)\n",
    "\n",
    "hp_preds = hp_clf.predict(X_test)\n",
    "\n",
    "print('High Performance XGB Regressor RMSLE:', root_mean_squared_log_error(y_test, hp_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(X['SaleCondition']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X['YearBuilt'].head())\n",
    "print('\\n')\n",
    "print(X['YearRemodAdd'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(X['YrSold']))\n",
    "print(set(X['MoSold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(X['ExterQual']))\n",
    "print(set(X['ExterCond']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(X['YearBuilt']))\n",
    "print('\\n')\n",
    "print(set(X['OverallQual']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(X['BedroomAbvGr']))\n",
    "print(set(X['FullBath']))\n",
    "print(set(X['HalfBath']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the features in the columns, a few things stand out:\n",
    "    \n",
    "  - Subtracting YearBuilt from YearRemodAdd determines how recent renovation was\n",
    "    completed (adds value to the house).\n",
    "  - Lot geometry can be determined by dividing LotArea by LotFrontage. If the       lot is a good shape, it'll sell better. If it's strange than it may be less\n",
    "    likely to sell.\n",
    "  - Location in Ames? Is their high crime in the area? What is the income          level     in the neighborhood?  Is     it close to the downtown area or accessible to              shopping/university/transit/major road networks?\n",
    "   \n",
    "  - Features to combine:\n",
    "       - YrSold and MoSold\n",
    "       - Condition1 and Condition2\n",
    "       - ExterQual and ExterCont\n",
    "       - YearBuilt and OverallQual\n",
    "       - Is there a finished basement?\n",
    "       - Finished basement sqft\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the features (X values)\n",
    "X_feat_eng = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the combined features\n",
    "X_feat_eng['YearsSinceReno'] = X_feat_eng['YearRemodAdd'] - X_feat_eng['YearBuilt']\n",
    "X_feat_eng['LotShape'] = X_feat_eng['LotArea'] / X_feat_eng['LotFrontage']\n",
    "X_feat_eng['LandTopo'] = X_feat_eng['LandSlope'] + '_' + X_feat_eng['LandContour']\n",
    "X_feat_eng['ValueRating'] = X_feat_eng['YearBuilt'] * X_feat_eng['OverallQual']\n",
    "X_feat_eng['FinishedBsmt'] = X_feat_eng['BsmtFinSF1'] > 0\n",
    "X_feat_eng['GarageVal'] = X_feat_eng['YearBuilt'] * X_feat_eng['GarageCars']\n",
    "X_feat_eng['MiscVal'] = X_feat_eng['Fireplaces'] + X_feat_eng['OverallQual']  \n",
    "X_feat_eng = X_feat_eng.drop(columns=['GarageCars'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data up in to numerical data (int and float) and categorical \n",
    "# data (objects, names, words etc.)\n",
    "feat_num_cols = [cname for cname in X_feat_eng.columns \n",
    "            if X_feat_eng[cname].dtype in ['float32']]\n",
    "\n",
    "feat_category_cols = [cname for cname in X_feat_eng.columns \n",
    "                 if X_feat_eng[cname].nunique() < 22 and \n",
    "                 X_feat_eng[cname].dtype in ['object', 'bool']]\n",
    "\n",
    "# SimpleImputer is a function that replaces null cell values with the mean,\n",
    "# median, most frequent or a fixed value based on the dataset used\n",
    "feat_numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# The same process can be applied to categorical values (strings, objects, etc.)\n",
    "# and automated using the Pipeline function\n",
    "feat_categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Transform all data in columns using the preprocessor and ColumnTransformer function\n",
    "feature_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', feat_numerical_transformer, feat_num_cols),\n",
    "        ('cat', feat_categorical_transformer, feat_category_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the final Feature model (XGBRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.6, gamma=0.0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.02, max_delta_step=0, max_depth=4,\n",
    "             min_child_weight=0.0, monotone_constraints='()',\n",
    "             n_estimators=1250, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "\n",
    "feature_clf = Pipeline(steps=[('feature_preprocessor', feature_preprocessor),\n",
    "                                ('feature_model', feature_model)           \n",
    "                                ])\n",
    "# Perform train-test split\n",
    "feature_X_train, feature_X_valid, feature_y_train, feature_y_valid = train_test_split(X_feat_eng, y, random_state=42)\n",
    "\n",
    "# Fit the training dataset\n",
    "feature_clf.fit(feature_X_train, feature_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = feature_clf.named_steps['feature_model']\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "\n",
    "feature_important = model.get_booster().get_score(importance_type='gain')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"SCORE\"]).sort_values(by = \"SCORE\", ascending=False)\n",
    "data['FEATURE_IMPORTANCE_KEY'] = data.index\n",
    "data.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# The size of the beta coefficient for each Feature in the model affects the SalePrice by a certain amount\n",
    "df_beta = pd.DataFrame(zip(X_train.columns, model.get_booster().get_score(importance_type='gain')), columns=['FEATURE','FEATURE_IMPORTANCE_KEY'])\n",
    "\n",
    "df_feat = pd.merge(df_beta, data, on='FEATURE_IMPORTANCE_KEY', how='inner')\n",
    "df_feat = df_feat.sort_values(by='FEATURE_IMPORTANCE_KEY',ascending=True).reset_index(drop=True)\n",
    "df_feat['FEATURE_IMPORTANCE_KEY'] = df_feat['FEATURE_IMPORTANCE_KEY'].str.replace('f','')\n",
    "df_feat['FEATURE_IMPORTANCE_KEY'] = df_feat['FEATURE_IMPORTANCE_KEY'].astype('int32')\n",
    "df_feat['SCORE'] = df_feat['SCORE'] / 10**6\n",
    "df_feat = df_feat.sort_values(by='SCORE',ascending=False).reset_index(drop=True)\n",
    "df_feat = df_feat.head(10)\n",
    "\n",
    "# Display top 20 features for XGBoost model\n",
    "fig = px.bar(df_feat,\n",
    "             x='SCORE',\n",
    "             y='FEATURE',\n",
    "             hover_data=['FEATURE',\n",
    "                        'SCORE'],\n",
    "            title='XGBoost Final Regression Model: Feature Importance Score - Importance Type = Gain')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature predictions using validation feature data (test)\n",
    "feature_preds = feature_clf.predict(feature_X_valid)\n",
    "\n",
    "print('Final XGBRegressor Model RMSLE:', root_mean_squared_log_error(feature_y_valid, feature_preds))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf4d54fbd1aa67388c0b0b70ec3753651b0e16d7eeb31ef24b0b3bf91c5c03b6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('gis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
